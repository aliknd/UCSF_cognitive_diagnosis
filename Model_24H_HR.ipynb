{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb3aba43-4ad0-4fa9-9158-996c75ce1c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Modelling helpers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (classification_report,\n",
    "                             confusion_matrix,\n",
    "                             balanced_accuracy_score,\n",
    "                             f1_score)\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0eb267-2349-41ef-924c-e717100c0a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"./\")          # folder that contains the CSV/XLSX\n",
    "HR_FILE  = DATA_DIR / \"heartrate_15min.csv\"\n",
    "DX_FILE  = DATA_DIR / \"Diagnoses_20250404.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b174bbb-f6bd-44d5-89da-19aa7f183cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labelled participants with HR data = 235\n"
     ]
    }
   ],
   "source": [
    "hr   = pd.read_csv(HR_FILE,  parse_dates=[\"Time\"])\n",
    "diag = pd.read_csv(DX_FILE,  parse_dates=[\"DCDate.diagnosis_baseline\"])\n",
    "\n",
    "# three-group label already prepared in the file\n",
    "KEEP_COLS = [\"PIDN\", \"DCDate.diagnosis_baseline\", \"Diagnosis_baseline_3groups\"]\n",
    "diag = diag[KEEP_COLS]\n",
    "\n",
    "# intersection\n",
    "labelled_pidns = set(diag.PIDN) & set(hr.PIDN)\n",
    "hr   = hr [hr.PIDN.isin(labelled_pidns)].copy()\n",
    "diag = diag[diag.PIDN.isin(labelled_pidns)].copy()\n",
    "\n",
    "print(f\"Labelled participants with HR data = {diag.PIDN.nunique()}\")   # 235\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3508ed-7763-41ee-aa0e-30c0603809d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235\n"
     ]
    }
   ],
   "source": [
    "def baseline_window(hr_grp, baseline_date):\n",
    "    \"\"\"\n",
    "    Return HR rows belonging to the first 24-h “day” that starts\n",
    "    on or after the baseline diagnosis date.\n",
    "    If none exist on/after that date, fall back to the first HR day available.\n",
    "    \"\"\"\n",
    "    # rows on/after baseline date\n",
    "    after = hr_grp[hr_grp.Time.dt.date >= baseline_date]\n",
    "    if after.empty:\n",
    "        day0 = hr_grp.Time.dt.date.min()\n",
    "    else:\n",
    "        day0 = after.Time.dt.date.min()\n",
    "    return hr_grp[hr_grp.Time.dt.date == day0]\n",
    "\n",
    "# add baseline date column for a quick merge\n",
    "diag = diag.rename(columns={\"DCDate.diagnosis_baseline\": \"BaselineDate\"})\n",
    "hr    = hr.merge(diag[[\"PIDN\", \"BaselineDate\"]], on=\"PIDN\", how=\"left\")\n",
    "\n",
    "baseline_slices = []\n",
    "for pid, grp in hr.groupby(\"PIDN\"):\n",
    "    rows = baseline_window(grp, grp[\"BaselineDate\"].iloc[0].date())\n",
    "    if not rows.empty:\n",
    "        baseline_slices.append(rows)\n",
    "\n",
    "baseline_hr = pd.concat(baseline_slices, ignore_index=True)\n",
    "print(baseline_hr.PIDN.nunique())    # should still be 235 (all have at least 1 day)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10db3332-3e57-4c98-a68b-f584c8fefb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved feature table -> baseline_hr_features.csv   (shape = (235, 14))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIDN</th>\n",
       "      <th>hr_mean</th>\n",
       "      <th>hr_median</th>\n",
       "      <th>hr_std</th>\n",
       "      <th>hr_min</th>\n",
       "      <th>hr_max</th>\n",
       "      <th>hr_iqr</th>\n",
       "      <th>hr_p10</th>\n",
       "      <th>hr_p90</th>\n",
       "      <th>tachy_prop</th>\n",
       "      <th>rmssd</th>\n",
       "      <th>day_mean</th>\n",
       "      <th>night_mean</th>\n",
       "      <th>Diagnosis_baseline_3groups</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1416</td>\n",
       "      <td>76.222222</td>\n",
       "      <td>71.0</td>\n",
       "      <td>12.447916</td>\n",
       "      <td>67.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>70.0</td>\n",
       "      <td>88.2</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>14.397712</td>\n",
       "      <td>76.588235</td>\n",
       "      <td>70.00000</td>\n",
       "      <td>Clinically Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2502</td>\n",
       "      <td>76.830189</td>\n",
       "      <td>77.0</td>\n",
       "      <td>10.720701</td>\n",
       "      <td>60.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>62.2</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>3.705505</td>\n",
       "      <td>79.488889</td>\n",
       "      <td>61.87500</td>\n",
       "      <td>Clinically Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2692</td>\n",
       "      <td>82.512195</td>\n",
       "      <td>82.0</td>\n",
       "      <td>7.951444</td>\n",
       "      <td>70.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.362117</td>\n",
       "      <td>83.153846</td>\n",
       "      <td>70.00000</td>\n",
       "      <td>Clinically Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3700</td>\n",
       "      <td>67.479167</td>\n",
       "      <td>66.0</td>\n",
       "      <td>6.154232</td>\n",
       "      <td>58.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.387782</td>\n",
       "      <td>67.156250</td>\n",
       "      <td>68.12500</td>\n",
       "      <td>Clinically Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3835</td>\n",
       "      <td>72.322917</td>\n",
       "      <td>70.0</td>\n",
       "      <td>15.271498</td>\n",
       "      <td>52.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.072917</td>\n",
       "      <td>8.758755</td>\n",
       "      <td>76.343750</td>\n",
       "      <td>64.28125</td>\n",
       "      <td>Clinically Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PIDN    hr_mean  hr_median     hr_std  hr_min  hr_max  hr_iqr  hr_p10  \\\n",
       "0  1416  76.222222       71.0  12.447916    67.0   115.0    4.75    70.0   \n",
       "1  2502  76.830189       77.0  10.720701    60.0   103.0   18.00    62.2   \n",
       "2  2692  82.512195       82.0   7.951444    70.0   100.0   10.00    71.0   \n",
       "3  3700  67.479167       66.0   6.154232    58.0    84.0   10.00    61.0   \n",
       "4  3835  72.322917       70.0  15.271498    52.0   110.0   21.00    55.0   \n",
       "\n",
       "   hr_p90  tachy_prop      rmssd   day_mean  night_mean  \\\n",
       "0    88.2    0.111111  14.397712  76.588235    70.00000   \n",
       "1    91.0    0.018868   3.705505  79.488889    61.87500   \n",
       "2    90.0    0.000000   8.362117  83.153846    70.00000   \n",
       "3    76.0    0.000000   4.387782  67.156250    68.12500   \n",
       "4    97.0    0.072917   8.758755  76.343750    64.28125   \n",
       "\n",
       "  Diagnosis_baseline_3groups  \n",
       "0          Clinically Normal  \n",
       "1          Clinically Normal  \n",
       "2          Clinically Normal  \n",
       "3          Clinically Normal  \n",
       "4          Clinically Normal  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------- 3  FEATURE ENGINEERING (robust version) -----------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def extract_features(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"Compute 24-h HR summary stats for one participant-day.\"\"\"\n",
    "    v = df[\"Value\"].to_numpy()\n",
    "    n = v.size\n",
    "\n",
    "    # Day (06-22) vs night masks\n",
    "    hours      = df.Time.dt.hour\n",
    "    day_mask   = hours.between(6, 21)\n",
    "    night_mask = ~day_mask\n",
    "\n",
    "    # Helpers that avoid warnings\n",
    "    safe_mean = lambda arr: np.nan if arr.size == 0 else arr.mean()\n",
    "    safe_pct  = lambda cond: np.nan if n == 0 else cond.mean()\n",
    "\n",
    "    return pd.Series({\n",
    "        \"hr_mean\"   : safe_mean(v),\n",
    "        \"hr_median\" : np.nan if n == 0 else np.median(v),\n",
    "        \"hr_std\"    : np.nan if n == 0 else np.std(v, ddof=0),     # no DoF warning\n",
    "        \"hr_min\"    : np.nan if n == 0 else v.min(),\n",
    "        \"hr_max\"    : np.nan if n == 0 else v.max(),\n",
    "        \"hr_iqr\"    : np.nan if n == 0 else np.percentile(v, 75) - np.percentile(v, 25),\n",
    "        \"hr_p10\"    : np.nan if n == 0 else np.percentile(v, 10),\n",
    "        \"hr_p90\"    : np.nan if n == 0 else np.percentile(v, 90),\n",
    "        \"tachy_prop\": safe_pct(v > 100),                            # proportion > 100 bpm\n",
    "        \"rmssd\"     : np.nan if n < 2 else np.sqrt(np.mean(np.diff(v)**2)),\n",
    "        \"day_mean\"  : safe_mean(df.loc[day_mask,   \"Value\"].to_numpy()),\n",
    "        \"night_mean\": safe_mean(df.loc[night_mask, \"Value\"].to_numpy())\n",
    "    })\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Build per-participant feature table\n",
    "feature_rows = (\n",
    "    baseline_hr\n",
    "      .groupby(\"PIDN\", group_keys=False)\n",
    "      .apply(extract_features, include_groups=False)   # silences future pandas warning\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Attach 3-group diagnosis label\n",
    "data = feature_rows.merge(\n",
    "    diag[[\"PIDN\", \"Diagnosis_baseline_3groups\"]],\n",
    "    on=\"PIDN\"\n",
    ")\n",
    "\n",
    "# ----- SAVE to CSV so you can reuse it later -----\n",
    "OUTFILE = \"baseline_hr_features.csv\"\n",
    "data.to_csv(OUTFILE, index=False)\n",
    "print(f\"Saved feature table -> {OUTFILE}   (shape = {data.shape})\")\n",
    "\n",
    "# quick peek\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "415ae3a2-71fa-4c02-a697-74c27b3dd4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      " hr_mean        0\n",
      "hr_median      0\n",
      "hr_std         0\n",
      "hr_min         0\n",
      "hr_max         0\n",
      "hr_iqr         0\n",
      "hr_p10         0\n",
      "hr_p90         0\n",
      "tachy_prop     0\n",
      "rmssd          6\n",
      "day_mean       7\n",
      "night_mean    23\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ----------------- rebuild X / y (drop PIDN) -----------------\n",
    "X = data.drop(columns=[\"Diagnosis_baseline_3groups\", \"PIDN\"])\n",
    "y = data[\"Diagnosis_baseline_3groups\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# handy diagnostic\n",
    "print(\"Missing values per column:\\n\", X_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92b176bb-5076-4d01-8601-f2ac4dbb772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression\n",
      "Balanced accuracy: 0.205\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Clinically Normal       0.57      0.43      0.49        30\n",
      "     FTD syndrome       0.00      0.00      0.00         6\n",
      "           MCI/AD       0.15      0.18      0.17        11\n",
      "\n",
      "         accuracy                           0.32        47\n",
      "        macro avg       0.24      0.21      0.22        47\n",
      "     weighted avg       0.40      0.32      0.35        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------- 5-a  Logistic Regression -----------------\n",
    "logreg = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),      # NEW\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(max_iter=1000,\n",
    "                       class_weight=\"balanced\",\n",
    "                       random_state=RANDOM_STATE)\n",
    ")\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "\n",
    "print(\"\\nLogistic Regression\")\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_lr).round(3))\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f936137-7890-4804-94b7-d31c83e437d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest\n",
      "Balanced accuracy: 0.289\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Clinically Normal       0.62      0.87      0.72        30\n",
      "     FTD syndrome       0.00      0.00      0.00         6\n",
      "           MCI/AD       0.00      0.00      0.00        11\n",
      "\n",
      "         accuracy                           0.55        47\n",
      "        macro avg       0.21      0.29      0.24        47\n",
      "     weighted avg       0.40      0.55      0.46        47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ----------------- 5-b  Random Forest -----------------\n",
    "rf = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),      # NEW\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=400,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"\\nRandom Forest\")\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred_rf).round(3))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d69dcc8c-1deb-48eb-baed-f0cd3f309ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best CV balanced-accuracy: 0.3\n",
      "Best params: {'model__learning_rate': 0.05, 'model__max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import ADASYN\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, balanced_accuracy_score\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"impute\" , SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\"  , StandardScaler()),\n",
    "    (\"adasyn\" , ADASYN(random_state=RANDOM_STATE, sampling_strategy=\"auto\")),\n",
    "    (\"model\"  , HistGradientBoostingClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"model__learning_rate\": [0.05, 0.1],\n",
    "    \"model__max_depth\"    : [None, 3]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv,\n",
    "    scoring=make_scorer(balanced_accuracy_score),\n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "gs.fit(X, y)\n",
    "print(\"Best CV balanced-accuracy:\", gs.best_score_.round(3))\n",
    "print(\"Best params:\", gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac82fc5e-90dd-480d-a657-69aa46172b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best CV balanced-accuracy: 0.302\n",
      "Params: {'adasyn__sampling_strategy': {0: 180, 1: 180, 2: 180}, 'model__learning_rate': 0.1, 'model__max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)          # 0, 1, 2\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"impute\" , SimpleImputer(strategy=\"median\")),\n",
    "    (\"scale\"  , StandardScaler()),\n",
    "    (\"adasyn\" , ADASYN(random_state=RANDOM_STATE)),\n",
    "    (\"model\"  , HistGradientBoostingClassifier(random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    # keeps the explicit target sizes\n",
    "    \"adasyn__sampling_strategy\": [{0:180, 1:180, 2:180}],\n",
    "    \"model__learning_rate\": [0.05, 0.1],\n",
    "    \"model__max_depth\"    : [None, 3]\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    pipe, param_grid, cv=cv,\n",
    "    scoring=make_scorer(balanced_accuracy_score),\n",
    "    n_jobs=-1, verbose=1\n",
    ")\n",
    "gs.fit(X, y_int)\n",
    "print(\"Best CV balanced-accuracy:\", gs.best_score_.round(3))\n",
    "print(\"Params:\", gs.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef9b793-164d-4d49-b00b-52cd5574f3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
